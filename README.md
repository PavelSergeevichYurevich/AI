AI-Backend приложение
пересылает запрос пользователя в LLM и возвращает структурированный ответ
(анализ, текст)

В рамках текущей итерации:
- каркас проекта FastAPI,
- `GET /health` и `GET /ready`,
- система конфигурации + `.env.example`,
- абстракция LLM-клиента (интерфейс + один провайдер),
- README с инструкцией локального запуска,
- базовые тесты для `health/ready`.

Вне рамок текущей итерации:
- `POST /analyze`,
- RAG/embeddings/pgvector,
- очереди/фоновые воркеры,
- продвинутая наблюдаемость,
- биллинг/подписки.

Цель Week 1 - заложить базовую архитектуру сервиса и абстракцию LLM-клиента



